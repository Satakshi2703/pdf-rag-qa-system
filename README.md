# PDF RAG QA System

**PDF RAG QA Tool** â€” Retrieve answers from any PDF using **FAISS**, **LangChain**, and your choice of local LLM: **Ollama (Llama3)** or **Qwen1.5**.

---

## ğŸ“Œ Overview

This project is a **Retrieval-Augmented Generation (RAG)** pipeline for question answering over PDF documents.  
You can:
- Extract text from any PDF
- Chunk and embed the text with **HuggingFace embeddings**
- Store & search chunks with **FAISS**
- Generate context-based answers using either:
  - âœ… **Ollama version:** Runs **Llama3.2:3b** via local Ollama server
  - âœ… **Qwen version:** Runs **Qwen1.5-0.5B** directly via HuggingFace Transformers

All **offline**, no cloud calls needed!

---

## ğŸ¯ Key Features

- ğŸ“„ PDF loader with LangChain `PyPDFLoader`
- âœ‚ï¸ Smart chunking with `RecursiveCharacterTextSplitter`
- ğŸ—‚ï¸ Local FAISS vector store for fast similarity search
- ğŸ” Terminal-based query loop
- ğŸ¤– Option to generate AI answers with your preferred LLM
- ğŸ§© Modular â€” choose Ollama backend or direct Transformers

---

## ğŸ“ Repository Structure

pdf-rag-qa-system/
â”‚
â”œâ”€â”€ ollama_version/
â”‚ â”œâ”€â”€ ollama_pdf_qa.py # Advanced Ollama-based RAG
â”‚
â”œâ”€â”€ qwen_version/
â”‚ â”œâ”€â”€ qwen_pdf_qa.py # Qwen1.5 version


---

## âš™ï¸ Tech Stack

- **Python**
- **LangChain**
- **FAISS**
- **HuggingFace Embeddings**
- **Ollama (Llama3.2:3b)**
- **Qwen1.5-0.5B** via Transformers
- **PyPDFLoader**

---

